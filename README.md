# Project_1

При проектировании хранилища данных для компании, занимающейся продажей электроники, осуществляем последовательность шагов.

1. Определяем задачу, которую решает хранилище. Допустим,у нас несколько задач. 
  Во-первых, нам нужно подготовить статистику продаж за несколько лет, т.е. мы собираем исторические данные. 
  Во-вторых, нам нужно повысить уровень сервиса, анализируя кол-во и причины возвратов. 
  В-третьих, нам нужно автоматизировать расчет KPI для менеджеров, а также расчет их премий на основании KPI.

2. Анализируем наличие и качество данных.
  Данные хранятся в 1С с достаточным уровнем качества, поставляются с личных кабинетов маркетплейсов и требуют предобработки, хранятся в Excel-файлах качество низкое, бывает много ошибок.

3. Проектируем модель данных для кажддого слоя. Для ДЗ модель делаем только для слоя DDS. 
  Схема нарисована отдельно.

4. Описываем путь данных по слоям stage-ods-dds-datamart.

    Слой сырых данных (Stage). Представляет собой отдельную хранения, куда данные попадают сразу после извлечения из исходных систем (1С, веб-сервисы, локальные файлы excel). 
    Здесь мы должны изолировать «сырые» данные от основной аналитической инфраструктуры и минимизировать нагрузку на боевые базы. 
    Сбои и несоответствие данных должны затронуть только этот слой, не оказывая влияние на следующие слои хранилища.
    На этом этапе выполняется глубокая трансформация базовая стандартизация (например, приведение типов данных, удаление дубликатов или форматирование временных меток). 
    Это упрощает последующий аудит, позволяет воспроизвести исторические выгрузки и служит удобной точкой входа для отладки данных до загрузки в ODS.
    В нашем случае мы забираем данные из 1C:ERP посредством экспортера и кладем их в MSSQL, либо ClickHouse.
    Однако, я с ClickHouse не работала, поэтому могу только предполагать, что с ним должно быть удобнее.
    К внутреннему серверу маркетплейсов подключаемся при помощи api. Забираем json и кладем их в Postgres. 
    Тут будет частое обновление и большой поток транзакций. Скорее всего тут целесообразно агрегировать таблицы в postgres.
    Файлы excel кладем в общую папку share, откуда автоматизируем забор и загрузку данных в MSSQL/ClickHouse посредством Apache Airflow. 
    

    Слой ODS (Operational Data Store) представляет собой промежуточный уровень между сырыми данными (Stage) и аналитическим хранилищем (DWH) или слоем DDS. 
    Тут данные из различных источников объединяются, очищаются и стандартизируются. 
    Этот слой важен для нашей оперативной отчетности — когда бизнесу нужно принимать решения на основе максимально свежих данных, не дожидаясь полной обработки и агрегации в DWH. 
    В ODS обычно хранятся данные в низкой степени агрегации, в формате, близком к исходному, но уже очищенные и согласованные по ключевым атрибутам.

    Слой DDS (Detail Data Store) — тут аккумулируются очищенные, нормализованные и агрегированные данные за длительный период времени. 
    Этот слой предоставляет устойчивый и оптимизированный для анализа источник информации, в отличие от оперативных хранилищ. 
    Здесь данные структурированы по темам, историзируются и подаются в виде удобных для аналитиков моделей (звезда, снежинка и др.). 
    Это позволяет выполнять сложные аналитические запросы без перегрузки оперативных баз. Данные загружаются после полной обработки реже, чем в слое ODS, обычно раз в день.

    Datamart — это слой DWH, спроектированный под потребности конкретных бизнес-пользователей или подразделений. 
    Он позволяет упростить и ускорить доступ к аналитике для конкретных отделов компании. 
    Datamart может включать только используемые атрибуты, быть денормализованным, отражать логику внутренних процессов компании и упрощать разработку BI-дашбордов.
